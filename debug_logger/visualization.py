#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¯è§†åŒ–è°ƒè¯•å·¥å…·

æä¾›å®æ—¶å’Œç¦»çº¿å¯è§†åŒ–åŠŸèƒ½ï¼Œç”¨äºåˆ†æpolicyæ¨ç†è¿‡ç¨‹
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
from typing import Dict, Any, Optional, List, Tuple
import json
from datetime import datetime


class DebugVisualizer:
    """è°ƒè¯•å¯è§†åŒ–å·¥å…·"""
    
    def __init__(self, log_dir: str = "debug_logs"):
        """
        åˆå§‹åŒ–å¯è§†åŒ–å·¥å…·
        
        Args:
            log_dir: æ—¥å¿—ç›®å½•è·¯å¾„
        """
        self.log_dir = Path(log_dir)
        self.images_dir = self.log_dir / "images"
        self.data_dir = self.log_dir / "data"
        
        # è®¾ç½®matplotlibä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        print(f"ğŸ¨ å¯è§†åŒ–å·¥å…·å·²åˆå§‹åŒ–: {self.log_dir}")
    
    def create_debug_image(self, 
                          cam_image: np.ndarray,
                          eih_image: np.ndarray,
                          joint_action: np.ndarray,
                          gripper_action: int,
                          gripper_width: float,
                          step: int,
                          inference_time: float = 0.0,
                          anomalies: List[str] = None) -> np.ndarray:
        """
        åˆ›å»ºè°ƒè¯•å›¾åƒï¼Œæ˜¾ç¤ºè¾“å…¥å’Œé¢„æµ‹ç»“æœ
        
        Args:
            cam_image: CAMå›¾åƒ
            eih_image: EIHå›¾åƒ
            joint_action: å…³èŠ‚åŠ¨ä½œ (8ç»´)
            gripper_action: gripperç¼–ç å™¨å€¼
            gripper_width: gripperç‰©ç†å®½åº¦
            step: æ­¥æ•°
            inference_time: æ¨ç†æ—¶é—´
            anomalies: å¼‚å¸¸åˆ—è¡¨
            
        Returns:
            np.ndarray: åˆæˆçš„è°ƒè¯•å›¾åƒ
        """
        # è°ƒæ•´å›¾åƒå¤§å°
        cam_resized = cv2.resize(cam_image, (320, 240))
        eih_resized = cv2.resize(eih_image, (320, 240))
        
        # åˆ›å»ºä¸»ç”»å¸ƒ
        canvas = np.zeros((600, 800, 3), dtype=np.uint8)
        
        # æ”¾ç½®å›¾åƒ
        canvas[20:260, 20:340] = cam_resized
        canvas[20:260, 380:700] = eih_resized
        
        # æ·»åŠ æ ‡é¢˜
        cv2.putText(canvas, f"Step: {step}", (20, 300), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
        cv2.putText(canvas, f"Time: {inference_time:.3f}s", (20, 330), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        # ç»˜åˆ¶å…³èŠ‚åŠ¨ä½œæŸ±çŠ¶å›¾
        joint_x = 20
        joint_y = 350
        joint_width = 30
        joint_height = 100
        
        for i, action in enumerate(joint_action):
            x = joint_x + i * (joint_width + 10)
            height = int(abs(action) * joint_height * 2)  # ç¼©æ”¾æ˜¾ç¤º
            color = (0, 255, 0) if action >= 0 else (0, 0, 255)
            
            cv2.rectangle(canvas, 
                         (x, joint_y + joint_height - height),
                         (x + joint_width, joint_y + joint_height),
                         color, -1)
            
            # æ·»åŠ å…³èŠ‚æ ‡ç­¾
            cv2.putText(canvas, f"J{i}", (x, joint_y + joint_height + 20), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        # ç»˜åˆ¶gripperä¿¡æ¯
        gripper_x = 500
        gripper_y = 350
        
        cv2.putText(canvas, f"Gripper:", (gripper_x, gripper_y), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
        cv2.putText(canvas, f"Encoder: {gripper_action}", (gripper_x, gripper_y + 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
        cv2.putText(canvas, f"Width: {gripper_width:.3f}m", (gripper_x, gripper_y + 50), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
        
        # ç»˜åˆ¶gripperçŠ¶æ€æ¡
        gripper_bar_width = 200
        gripper_bar_height = 20
        gripper_progress = gripper_action / 255.0
        
        cv2.rectangle(canvas, (gripper_x, gripper_y + 70), 
                     (gripper_x + gripper_bar_width, gripper_y + 70 + gripper_bar_height),
                     (100, 100, 100), -1)
        cv2.rectangle(canvas, (gripper_x, gripper_y + 70), 
                     (gripper_x + int(gripper_progress * gripper_bar_width), gripper_y + 70 + gripper_bar_height),
                     (0, 255, 0), -1)
        
        # æ˜¾ç¤ºå¼‚å¸¸ä¿¡æ¯
        if anomalies:
            anomaly_y = 500
            cv2.putText(canvas, "Anomalies:", (20, anomaly_y), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
            for i, anomaly in enumerate(anomalies):
                cv2.putText(canvas, f"- {anomaly}", (20, anomaly_y + 25 + i * 20), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)
        
        return canvas
    
    def create_action_timeline(self, records: List[Dict[str, Any]], 
                              output_path: Optional[str] = None) -> str:
        """
        åˆ›å»ºåŠ¨ä½œæ—¶é—´çº¿å›¾
        
        Args:
            records: æ¨ç†è®°å½•åˆ—è¡¨
            output_path: è¾“å‡ºè·¯å¾„
            
        Returns:
            str: ä¿å­˜è·¯å¾„
        """
        if not records:
            print("âš ï¸  æ²¡æœ‰è®°å½•æ•°æ®")
            return ""
        
        # æå–æ•°æ®
        steps = [r["step"] for r in records]
        joint_actions = [r["output"]["joint_action"] for r in records if "joint_action" in r["output"]]
        gripper_actions = [r["output"]["gripper_action"] for r in records if "gripper_action" in r["output"]]
        inference_times = [r["metadata"].get("inference_time", 0) for r in records]
        
        if not joint_actions:
            print("âš ï¸  æ²¡æœ‰å…³èŠ‚åŠ¨ä½œæ•°æ®")
            return ""
        
        # åˆ›å»ºå›¾å½¢
        fig, axes = plt.subplots(3, 1, figsize=(15, 10))
        
        # å…³èŠ‚åŠ¨ä½œæ—¶é—´çº¿
        joint_actions = np.array(joint_actions)
        for i in range(joint_actions.shape[1]):
            axes[0].plot(steps, joint_actions[:, i], label=f'Joint {i}', alpha=0.7)
        axes[0].set_title('Joint Actions Over Time')
        axes[0].set_ylabel('Action Value')
        axes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        axes[0].grid(True, alpha=0.3)
        
        # GripperåŠ¨ä½œæ—¶é—´çº¿
        if gripper_actions:
            axes[1].plot(steps, gripper_actions, 'b-', linewidth=2, label='Gripper Action')
            axes[1].set_title('Gripper Action Over Time')
            axes[1].set_ylabel('Encoder Value')
            axes[1].legend()
            axes[1].grid(True, alpha=0.3)
        
        # æ¨ç†æ—¶é—´
        if inference_times:
            axes[2].plot(steps, inference_times, 'r-', linewidth=2, label='Inference Time')
            axes[2].set_title('Inference Time Over Time')
            axes[2].set_xlabel('Step')
            axes[2].set_ylabel('Time (s)')
            axes[2].legend()
            axes[2].grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾åƒ
        if not output_path:
            output_path = self.log_dir / f"action_timeline_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
        
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"ğŸ“ˆ åŠ¨ä½œæ—¶é—´çº¿å·²ä¿å­˜: {output_path}")
        return str(output_path)
    
    def create_action_distribution(self, records: List[Dict[str, Any]], 
                                  output_path: Optional[str] = None) -> str:
        """
        åˆ›å»ºåŠ¨ä½œåˆ†å¸ƒå›¾
        
        Args:
            records: æ¨ç†è®°å½•åˆ—è¡¨
            output_path: è¾“å‡ºè·¯å¾„
            
        Returns:
            str: ä¿å­˜è·¯å¾„
        """
        if not records:
            print("âš ï¸  æ²¡æœ‰è®°å½•æ•°æ®")
            return ""
        
        # æå–å…³èŠ‚åŠ¨ä½œæ•°æ®
        joint_actions = []
        for r in records:
            if "joint_action" in r["output"]:
                joint_actions.append(r["output"]["joint_action"])
        
        if not joint_actions:
            print("âš ï¸  æ²¡æœ‰å…³èŠ‚åŠ¨ä½œæ•°æ®")
            return ""
        
        joint_actions = np.array(joint_actions)
        
        # åˆ›å»ºå›¾å½¢
        fig, axes = plt.subplots(2, 4, figsize=(16, 8))
        axes = axes.flatten()
        
        for i in range(min(8, joint_actions.shape[1])):
            axes[i].hist(joint_actions[:, i], bins=50, alpha=0.7, edgecolor='black')
            axes[i].set_title(f'Joint {i} Action Distribution')
            axes[i].set_xlabel('Action Value')
            axes[i].set_ylabel('Frequency')
            axes[i].grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾åƒ
        if not output_path:
            output_path = self.log_dir / f"action_distribution_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
        
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"ğŸ“Š åŠ¨ä½œåˆ†å¸ƒå›¾å·²ä¿å­˜: {output_path}")
        return str(output_path)
    
    def create_debug_video(self, 
                          records: List[Dict[str, Any]], 
                          output_path: Optional[str] = None,
                          fps: int = 10) -> str:
        """
        åˆ›å»ºè°ƒè¯•è§†é¢‘
        
        Args:
            records: æ¨ç†è®°å½•åˆ—è¡¨
            output_path: è¾“å‡ºè·¯å¾„
            fps: è§†é¢‘å¸§ç‡
            
        Returns:
            str: ä¿å­˜è·¯å¾„
        """
        if not records:
            print("âš ï¸  æ²¡æœ‰è®°å½•æ•°æ®")
            return ""
        
        if not output_path:
            output_path = self.log_dir / f"debug_video_{datetime.now().strftime('%Y%m%d_%H%M%S')}.mp4"
        
        # è®¾ç½®è§†é¢‘ç¼–ç å™¨
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(str(output_path), fourcc, fps, (800, 600))
        
        print(f"ğŸ¬ å¼€å§‹åˆ›å»ºè°ƒè¯•è§†é¢‘...")
        
        for i, record in enumerate(records):
            # åŠ è½½å›¾åƒ
            cam_path = record["input"].get("cam_image_path")
            eih_path = record["input"].get("eih_image_path")
            
            if not cam_path or not eih_path:
                continue
            
            try:
                cam_image = cv2.imread(cam_path)
                eih_image = cv2.imread(eih_path)
                
                if cam_image is None or eih_image is None:
                    continue
                
                # åˆ›å»ºè°ƒè¯•å›¾åƒ
                debug_image = self.create_debug_image(
                    cam_image=cam_image,
                    eih_image=eih_image,
                    joint_action=np.array(record["output"]["joint_action"]),
                    gripper_action=record["output"]["gripper_action"],
                    gripper_width=record["output"].get("gripper_width", 0.0),
                    step=record["step"],
                    inference_time=record["metadata"].get("inference_time", 0.0)
                )
                
                out.write(debug_image)
                
                if i % 100 == 0:
                    print(f"  å¤„ç†è¿›åº¦: {i}/{len(records)}")
                    
            except Exception as e:
                print(f"âš ï¸  å¤„ç†è®°å½• {i} æ—¶å‡ºé”™: {e}")
                continue
        
        out.release()
        print(f"ğŸ¬ è°ƒè¯•è§†é¢‘å·²ä¿å­˜: {output_path}")
        return str(output_path)
    
    def load_records_from_files(self, max_records: int = 1000) -> List[Dict[str, Any]]:
        """
        ä»æ–‡ä»¶åŠ è½½è®°å½•
        
        Args:
            max_records: æœ€å¤§åŠ è½½è®°å½•æ•°
            
        Returns:
            List[Dict[str, Any]]: è®°å½•åˆ—è¡¨
        """
        records = []
        data_files = sorted(self.data_dir.glob("*.json"))
        
        for i, file_path in enumerate(data_files):
            if i >= max_records:
                break
                
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    record = json.load(f)
                    records.append(record)
            except Exception as e:
                print(f"âš ï¸  åŠ è½½æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
                continue
        
        print(f"ğŸ“ å·²åŠ è½½ {len(records)} æ¡è®°å½•")
        return records
