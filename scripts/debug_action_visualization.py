#!/usr/bin/env python3
"""
å…³èŠ‚åŠ¨ä½œçªå˜åˆ†æè„šæœ¬
ä¸“æ³¨äºåˆ†æACTæ¨¡å‹æ¨ç†è¿‡ç¨‹ä¸­çš„å…³èŠ‚ä½ç½®çªå˜
"""

import os
import sys
import numpy as np
from pathlib import Path
import argparse
import time
import json
from collections import deque
import threading

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_dir = Path(__file__).parent.parent
model_lerobot_path = project_dir / "model" / "lerobot" / "src"
sys.path.insert(0, str(model_lerobot_path))
sys.path.insert(0, str(project_dir))

# å¯¼å…¥å¿…è¦çš„æ¨¡å—
from common.gripper_util import convert_gripper_width_to_encoder
from lerobot.policies.act.modeling_act import ACTPolicy
from lerobot.constants import OBS_IMAGES, ACTION, OBS_STATE
from policy_interface import create_policy_interface
from common.precise_sleep import precise_wait

# ç›¸æœºç›¸å…³å¯¼å…¥
import pyrealsense2 as rs
from r3kit.devices.camera.realsense import config as rs_cfg
from r3kit.devices.camera.realsense.d415 import D415

class ActionDataCollector:
    """åŠ¨ä½œæ•°æ®æ”¶é›†å™¨"""
    
    def __init__(self, max_history=1000):
        self.max_history = max_history
        
        # åŠ¨ä½œæ•°æ®å­˜å‚¨
        self.timestamps = deque(maxlen=max_history)
        self.joint_actions = deque(maxlen=max_history)  # 7ç»´å…³èŠ‚åŠ¨ä½œ
        self.gripper_actions = deque(maxlen=max_history)  # 1ç»´å¤¹çˆªåŠ¨ä½œ
        self.full_actions = deque(maxlen=max_history)  # 8ç»´å®Œæ•´åŠ¨ä½œ
        
        # æ¨ç†æ€§èƒ½æ•°æ®
        self.inference_times = deque(maxlen=max_history)
        self.action_change_rates = deque(maxlen=max_history)
        
        # çªå˜æ£€æµ‹æ•°æ®
        self.mutation_threshold = 0.1  # çªå˜é˜ˆå€¼ (rad)
        self.mutations = []  # å­˜å‚¨çªå˜ä¿¡æ¯
        
        # çº¿ç¨‹å®‰å…¨
        self.lock = threading.Lock()
        
    def add_action(self, action, inference_time, action_type="normal"):
        """æ·»åŠ åŠ¨ä½œæ•°æ®"""
        with self.lock:
            current_time = time.monotonic()
            
            # å­˜å‚¨æ•°æ®
            self.timestamps.append(current_time)
            self.joint_actions.append(action[:7].copy())
            self.gripper_actions.append(action[7])
            self.full_actions.append(action.copy())
            self.inference_times.append(inference_time)
            
            # è®¡ç®—åŠ¨ä½œå˜åŒ–ç‡å’Œæ£€æµ‹çªå˜
            if len(self.joint_actions) > 1:
                prev_joint = self.joint_actions[-2]
                curr_joint = self.joint_actions[-1]
                change_rate = np.linalg.norm(curr_joint - prev_joint)
                self.action_change_rates.append(change_rate)
                
                # æ£€æµ‹çªå˜
                if change_rate > self.mutation_threshold:
                    mutation_info = {
                        'step': len(self.joint_actions) - 1,
                        'timestamp': current_time,
                        'change_rate': float(change_rate),
                        'prev_joint_pos': prev_joint.tolist(),
                        'curr_joint_pos': curr_joint.tolist(),
                        'joint_changes': (curr_joint - prev_joint).tolist(),
                        'inference_time': float(inference_time),
                        'action_type': action_type
                    }
                    self.mutations.append(mutation_info)
                    
                    # æ‰“å°çªå˜ä¿¡æ¯
                    print(f"ğŸš¨ æ£€æµ‹åˆ°å…³èŠ‚çªå˜!")
                    print(f"  æ­¥éª¤: {mutation_info['step']}")
                    print(f"  æ—¶é—´: {current_time:.3f}s")
                    print(f"  å˜åŒ–ç‡: {change_rate:.6f} rad")
                    print(f"  å‰ä¸€æ­¥å…³èŠ‚ä½ç½®: {prev_joint}")
                    print(f"  å½“å‰å…³èŠ‚ä½ç½®: {curr_joint}")
                    print(f"  å…³èŠ‚å˜åŒ–: {curr_joint - prev_joint}")
                    print(f"  æ¨ç†æ—¶é—´: {inference_time:.3f}s")
                    print(f"  åŠ¨ä½œç±»å‹: {action_type}")
                    print("-" * 50)
            else:
                self.action_change_rates.append(0.0)
    
    def get_data(self):
        """è·å–å½“å‰æ•°æ®ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
        with self.lock:
            return {
                'timestamps': list(self.timestamps),
                'joint_actions': np.array(list(self.joint_actions)),
                'gripper_actions': list(self.gripper_actions),
                'full_actions': np.array(list(self.full_actions)),
                'inference_times': list(self.inference_times),
                'action_change_rates': list(self.action_change_rates),
                'mutations': self.mutations.copy()
            }
    
    def analyze_mutations(self):
        """åˆ†æçªå˜æ¨¡å¼"""
        if not self.mutations:
            print("æœªæ£€æµ‹åˆ°ä»»ä½•çªå˜")
            return
        
        print(f"\n=== çªå˜åˆ†ææŠ¥å‘Š ===")
        print(f"æ€»çªå˜æ¬¡æ•°: {len(self.mutations)}")
        
        # æŒ‰æ¨ç†æ—¶é—´åˆ†æçªå˜
        inference_time_mutations = [m for m in self.mutations if m['action_type'] == 'normal']
        fallback_mutations = [m for m in self.mutations if m['action_type'] == 'fallback']
        
        print(f"æ­£å¸¸æ¨ç†ä¸­çš„çªå˜: {len(inference_time_mutations)}")
        print(f"é™çº§ç­–ç•¥ä¸­çš„çªå˜: {len(fallback_mutations)}")
        
        if inference_time_mutations:
            print(f"\n--- æ­£å¸¸æ¨ç†çªå˜åˆ†æ ---")
            for i, mutation in enumerate(inference_time_mutations):
                print(f"çªå˜ {i+1}:")
                print(f"  æ­¥éª¤: {mutation['step']}")
                print(f"  å˜åŒ–ç‡: {mutation['change_rate']:.6f} rad")
                print(f"  æ¨ç†æ—¶é—´: {mutation['inference_time']:.3f}s")
                print(f"  ä¸»è¦å˜åŒ–å…³èŠ‚: {self._find_max_change_joint(mutation['joint_changes'])}")
        
        # åˆ†æçªå˜çš„æ—¶é—´æ¨¡å¼
        self._analyze_mutation_timing()
    
    def _find_max_change_joint(self, joint_changes):
        """æ‰¾åˆ°å˜åŒ–æœ€å¤§çš„å…³èŠ‚"""
        joint_changes = np.array(joint_changes)
        max_joint_idx = np.argmax(np.abs(joint_changes))
        return f"å…³èŠ‚{max_joint_idx+1} (å˜åŒ–: {joint_changes[max_joint_idx]:.4f} rad)"
    
    def _analyze_mutation_timing(self):
        """åˆ†æçªå˜çš„æ—¶é—´æ¨¡å¼"""
        if len(self.mutations) < 2:
            return
        
        print(f"\n--- çªå˜æ—¶é—´æ¨¡å¼åˆ†æ ---")
        
        # åˆ†æçªå˜é—´éš”
        intervals = []
        for i in range(1, len(self.mutations)):
            interval = self.mutations[i]['step'] - self.mutations[i-1]['step']
            intervals.append(interval)
        
        if intervals:
            print(f"çªå˜é—´éš”ç»Ÿè®¡:")
            print(f"  å¹³å‡é—´éš”: {np.mean(intervals):.1f} æ­¥")
            print(f"  æœ€å°é—´éš”: {np.min(intervals)} æ­¥")
            print(f"  æœ€å¤§é—´éš”: {np.max(intervals)} æ­¥")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰è§„å¾‹çš„é—´éš”ï¼ˆå¦‚25æ­¥é—´éš”ï¼‰
            interval_counts = {}
            for interval in intervals:
                interval_counts[interval] = interval_counts.get(interval, 0) + 1
            
            print(f"  é—´éš”åˆ†å¸ƒ: {dict(sorted(interval_counts.items()))}")
            
            # ç‰¹åˆ«æ£€æŸ¥25æ­¥é—´éš”
            if 25 in interval_counts:
                print(f"  âš ï¸ å‘ç°25æ­¥é—´éš”çš„çªå˜: {interval_counts[25]} æ¬¡")
                print(f"     è¿™å¯èƒ½ä¸ACTæ¨¡å‹çš„n_action_steps=25æœ‰å…³ï¼")
    
    def save_data(self, filepath):
        """ä¿å­˜æ•°æ®åˆ°æ–‡ä»¶"""
        data = self.get_data()
        # è½¬æ¢numpyæ•°ç»„ä¸ºåˆ—è¡¨ä»¥ä¾¿JSONåºåˆ—åŒ–
        for key in ['joint_actions', 'full_actions']:
            if key in data:
                data[key] = data[key].tolist()
        
        # è½¬æ¢æ‰€æœ‰numpyç±»å‹ä¸ºPythonåŸç”Ÿç±»å‹
        def convert_numpy_types(obj):
            if isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, (np.float32, np.float64)):
                return float(obj)
            elif isinstance(obj, (np.int32, np.int64)):
                return int(obj)
            elif isinstance(obj, list):
                return [convert_numpy_types(item) for item in obj]
            elif isinstance(obj, dict):
                return {k: convert_numpy_types(v) for k, v in obj.items()}
            else:
                return obj
        
        data = convert_numpy_types(data)
        
        with open(filepath, 'w') as f:
            json.dump(data, f, indent=2)
        print(f"åŠ¨ä½œæ•°æ®å·²ä¿å­˜åˆ°: {filepath}")


class ActionAnalyzer:
    """åŠ¨ä½œåˆ†æå™¨"""
    
    def __init__(self, data_collector, save_dir=None):
        self.data_collector = data_collector
        self.save_dir = save_dir or Path.cwd()
        
        # æ‰§è¡Œåˆ†æ
        self.run_analysis()
        
    def run_analysis(self):
        """è¿è¡Œåˆ†æ"""
        print("=== å¼€å§‹åŠ¨ä½œåˆ†æ ===")
        
        # åˆ†æçªå˜
        self.data_collector.analyze_mutations()
        
        # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
        self.generate_statistics_report()
        
        print("=== åˆ†æå®Œæˆ ===")
    
    def generate_statistics_report(self):
        """ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š"""
        data = self.data_collector.get_data()
        
        if len(data['timestamps']) == 0:
            print("æ²¡æœ‰æ•°æ®å¯åˆ†æ")
            return
        
        # ç”Ÿæˆæ—¶é—´æˆ³
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        
        # ç”Ÿæˆæ–‡æœ¬æŠ¥å‘Š
        self.save_statistics_report(data, timestamp)
    
    def save_statistics_report(self, data, timestamp):
        """ä¿å­˜ç»Ÿè®¡æŠ¥å‘Š"""
        timestamps = np.array(data['timestamps'])
        joint_actions = data['joint_actions']
        change_rates = data['action_change_rates']
        inference_times = data['inference_times']
        mutations = data['mutations']
        
        report_lines = []
        report_lines.append("=" * 80)
        report_lines.append("å…³èŠ‚åŠ¨ä½œçªå˜åˆ†ææŠ¥å‘Š")
        report_lines.append("=" * 80)
        report_lines.append(f"ç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}")
        report_lines.append("")
        
        # åŸºæœ¬ä¿¡æ¯
        report_lines.append("ã€åŸºæœ¬ä¿¡æ¯ã€‘")
        report_lines.append(f"æ€»æ­¥æ•°: {len(data['timestamps'])}")
        if len(timestamps) > 0:
            total_time = timestamps[-1] - timestamps[0]
            report_lines.append(f"æ€»è¿è¡Œæ—¶é—´: {total_time:.2f} ç§’")
            report_lines.append(f"å¹³å‡é¢‘ç‡: {len(timestamps)/total_time:.2f} Hz")
        report_lines.append("")
        
        # çªå˜åˆ†æ
        report_lines.append("ã€çªå˜åˆ†æã€‘")
        report_lines.append(f"æ£€æµ‹åˆ°çš„çªå˜æ€»æ•°: {len(mutations)}")
        report_lines.append(f"çªå˜é˜ˆå€¼: {self.data_collector.mutation_threshold} rad")
        report_lines.append("")
        
        if mutations:
            report_lines.append("è¯¦ç»†çªå˜ä¿¡æ¯:")
            for i, mutation in enumerate(mutations):
                report_lines.append(f"\nçªå˜ {i+1}:")
                report_lines.append(f"  æ­¥éª¤: {mutation['step']}")
                report_lines.append(f"  æ—¶é—´æˆ³: {mutation['timestamp']:.3f}")
                report_lines.append(f"  å˜åŒ–ç‡: {mutation['change_rate']:.6f} rad")
                report_lines.append(f"  æ¨ç†æ—¶é—´: {mutation['inference_time']:.3f}s")
                report_lines.append(f"  åŠ¨ä½œç±»å‹: {mutation['action_type']}")
                report_lines.append(f"  å‰ä¸€æ­¥å…³èŠ‚ä½ç½®: {mutation['prev_joint_pos']}")
                report_lines.append(f"  å½“å‰å…³èŠ‚ä½ç½®: {mutation['curr_joint_pos']}")
                report_lines.append(f"  å…³èŠ‚å˜åŒ–: {mutation['joint_changes']}")
                
                # æ‰¾å‡ºå˜åŒ–æœ€å¤§çš„å…³èŠ‚
                joint_changes = np.array(mutation['joint_changes'])
                max_joint_idx = np.argmax(np.abs(joint_changes))
                report_lines.append(f"  ä¸»è¦å˜åŒ–å…³èŠ‚: å…³èŠ‚{max_joint_idx+1} (å˜åŒ–: {joint_changes[max_joint_idx]:.4f} rad)")
        else:
            report_lines.append("æœªæ£€æµ‹åˆ°ä»»ä½•çªå˜")
        
        report_lines.append("")
        
        # æ¨ç†æ€§èƒ½åˆ†æ
        report_lines.append("ã€æ¨ç†æ€§èƒ½åˆ†æã€‘")
        if len(inference_times) > 0:
            report_lines.append(f"å¹³å‡æ¨ç†æ—¶é—´: {np.mean(inference_times):.4f} ç§’")
            report_lines.append(f"æœ€å¤§æ¨ç†æ—¶é—´: {np.max(inference_times):.4f} ç§’")
            report_lines.append(f"æœ€å°æ¨ç†æ—¶é—´: {np.min(inference_times):.4f} ç§’")
            report_lines.append(f"æ¨ç†æ—¶é—´æ ‡å‡†å·®: {np.std(inference_times):.4f} ç§’")
            
            timeout_count = sum(1 for t in inference_times if t > 0.18)
            report_lines.append(f"è¶…æ—¶æ¬¡æ•° (>0.18s): {timeout_count}")
            report_lines.append(f"è¶…æ—¶æ¯”ä¾‹: {timeout_count/len(inference_times)*100:.1f}%")
        report_lines.append("")
        
        # åŠ¨ä½œè´¨é‡åˆ†æ
        report_lines.append("ã€åŠ¨ä½œè´¨é‡åˆ†æã€‘")
        if len(change_rates) > 0:
            report_lines.append(f"å¹³å‡åŠ¨ä½œå˜åŒ–ç‡: {np.mean(change_rates):.6f} rad")
            report_lines.append(f"æœ€å¤§åŠ¨ä½œå˜åŒ–ç‡: {np.max(change_rates):.6f} rad")
            report_lines.append(f"åŠ¨ä½œå˜åŒ–ç‡æ ‡å‡†å·®: {np.std(change_rates):.6f} rad")
            
            high_change_count = sum(1 for rate in change_rates if rate > self.data_collector.mutation_threshold)
            report_lines.append(f"é«˜å˜åŒ–ç‡æ¬¡æ•° (>{self.data_collector.mutation_threshold} rad): {high_change_count}")
            report_lines.append(f"é«˜å˜åŒ–ç‡æ¯”ä¾‹: {high_change_count/len(change_rates)*100:.1f}%")
        report_lines.append("")
        
        # 25æ­¥é—´éš”åˆ†æ
        if len(mutations) > 1:
            report_lines.append("ã€25æ­¥é—´éš”åˆ†æã€‘")
            intervals = []
            for i in range(1, len(mutations)):
                interval = mutations[i]['step'] - mutations[i-1]['step']
                intervals.append(interval)
            
            interval_counts = {}
            for interval in intervals:
                interval_counts[interval] = interval_counts.get(interval, 0) + 1
            
            report_lines.append(f"çªå˜é—´éš”åˆ†å¸ƒ: {dict(sorted(interval_counts.items()))}")
            
            if 25 in interval_counts:
                report_lines.append(f"âš ï¸ å‘ç°{interval_counts[25]}æ¬¡25æ­¥é—´éš”çš„çªå˜ï¼")
                report_lines.append("     è¿™å¼ºçƒˆæš—ç¤ºçªå˜ä¸ACTæ¨¡å‹çš„n_action_steps=25æœ‰å…³")
                report_lines.append("     å»ºè®®æ£€æŸ¥æ¨¡å‹åœ¨æ¯æ¬¡æ¨ç†25æ­¥åçš„è¡Œä¸º")
            else:
                report_lines.append("æœªå‘ç°æ˜æ˜¾çš„25æ­¥é—´éš”æ¨¡å¼")
        
        report_lines.append("")
        report_lines.append("=" * 80)
        
        # ä¿å­˜æ–‡æœ¬æŠ¥å‘Š
        report_text = "\n".join(report_lines)
        report_path = self.save_dir / f"mutation_analysis_report_{timestamp}.txt"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_text)
        
        print(f"çªå˜åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
        
        # åŒæ—¶æ‰“å°åˆ°æ§åˆ¶å°
        print("\n" + report_text)


class DebugActionInferenceRunner:
    """å¸¦åŠ¨ä½œå¯è§†åŒ–çš„æ¨ç†è¿è¡Œå™¨"""
    
    def __init__(self, model_path, config_path, device="cuda", max_steps=1000, 
                 test_mode=False, frequency=10.0, use_eih=True):
        self.model_path = model_path
        self.config_path = config_path
        self.device = device
        self.max_steps = max_steps
        self.test_mode = test_mode
        self.frequency = frequency
        self.use_eih = use_eih
        
        # åˆ›å»ºæ•°æ®æ”¶é›†å™¨
        self.data_collector = ActionDataCollector()
        
        # åˆå§‹åŒ–ç›¸æœºç³»ç»Ÿï¼ˆå¤ç”¨åŸæœ‰ä»£ç ï¼‰
        self.camera_system = self._init_camera_system()
        
        # åˆå§‹åŒ–ACTç­–ç•¥ï¼ˆå¤ç”¨åŸæœ‰ä»£ç ï¼‰
        self.policy = self._init_policy()
        
        print(f"è°ƒè¯•æ¨ç†è¿è¡Œå™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"æ•°æ®æ”¶é›†å™¨å·²å¯åŠ¨ï¼Œæœ€å¤§å†å²è®°å½•: {self.data_collector.max_history}")
    
    def _init_camera_system(self):
        """åˆå§‹åŒ–ç›¸æœºç³»ç»Ÿï¼ˆå¤ç”¨åŸæœ‰ä»£ç ï¼‰"""
        # è¿™é‡Œå¤ç”¨åŸæœ‰çš„CameraSystemç±»
        from scripts.inference_with_policy_interface_updated import CameraSystem
        return CameraSystem()
    
    def _init_policy(self):
        """åˆå§‹åŒ–ç­–ç•¥ï¼ˆå¤ç”¨åŸæœ‰ä»£ç ï¼‰"""
        # è¿™é‡Œå¤ç”¨åŸæœ‰çš„ACTPolicyWrapperç±»
        from scripts.inference_with_policy_interface_updated import ACTPolicyWrapper
        return ACTPolicyWrapper(
            model_path=self.model_path,
            device=self.device,
            camera_system=self.camera_system,
            debug_image=False,
            use_eih=self.use_eih
        )
    
    def run_with_visualization(self):
        """è¿è¡Œæ¨ç†å¹¶å®æ—¶å¯è§†åŒ–"""
        print("å¯åŠ¨åŠ¨ä½œçªå˜åˆ†æ...")
        print("æ³¨æ„ï¼šåˆ†æå°†åœ¨æ•°æ®æ”¶é›†å®Œæˆåè¿›è¡Œ")
        
        try:
            if self.test_mode:
                print("ä½¿ç”¨æµ‹è¯•æ¨¡å¼è¿›è¡ŒåŠ¨ä½œåˆ†æ")
                self._run_test_mode_with_collection()
            else:
                print("ä½¿ç”¨å®æ—¶æ¨ç†æ¨¡å¼è¿›è¡ŒåŠ¨ä½œåˆ†æ")
                self._run_real_time_mode_with_collection()
        except KeyboardInterrupt:
            print("\nç”¨æˆ·ä¸­æ–­ï¼Œåœæ­¢åŠ¨ä½œåˆ†æ...")
        except Exception as e:
            print(f"å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
        finally:
            # ä¿å­˜æ•°æ®åˆ°è„šæœ¬æ‰€åœ¨ç›®å½•
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            script_dir = Path(__file__).parent
            save_path = script_dir / f"action_debug_data_{timestamp}.json"
            self.data_collector.save_data(str(save_path))
            
            # å¯åŠ¨åˆ†æ
            print("å¯åŠ¨çªå˜åˆ†æ...")
            analyzer = ActionAnalyzer(self.data_collector, save_dir=script_dir)
            
            # æ¸…ç†èµ„æº
            self.cleanup()
    
    def _run_test_mode_with_collection(self):
        """æµ‹è¯•æ¨¡å¼ï¼šæ”¶é›†åŠ¨ä½œæ•°æ®"""
        print("å¼€å§‹æµ‹è¯•æ¨ç†å¹¶æ”¶é›†åŠ¨ä½œæ•°æ®...")
        for i in range(100):  # è¿è¡Œ100æ­¥è¿›è¡Œæµ‹è¯•
            print(f"\n=== æµ‹è¯•æ¨ç† {i + 1} ===")
            
            # æ¨¡æ‹Ÿè§‚æµ‹æ•°æ®
            obs = {
                'robot0_joint_pos': np.random.uniform(-1, 1, 7),
                'robot0_joint_vel': np.random.uniform(-0.1, 0.1, 7),
                'robot0_eef_pos': np.random.uniform(0.3, 0.7, 3),
                'robot0_eef_rot_axis_angle': np.random.uniform(-1, 1, 3),
                'robot0_gripper_width': np.random.uniform(0.0, 0.08, 1),
                'timestamp': time.monotonic()
            }
            
            # æ‰§è¡Œç­–ç•¥å¹¶æµ‹é‡æ¨ç†æ—¶é—´
            t_start = time.monotonic()
            cur_action = self.policy(obs)
            t_end = time.monotonic()
            inference_time = t_end - t_start
            
            # æ”¶é›†åŠ¨ä½œæ•°æ®
            self.data_collector.add_action(cur_action, inference_time)
            
            print(f"æ¨ç†æ—¶é—´: {inference_time:.3f}s")
            print(f"åŠ¨ä½œ: {cur_action}")
            
            time.sleep(0.1)  # 100msé—´éš”
    
    def _run_real_time_mode_with_collection(self):
        """å®æ—¶æ¨ç†æ¨¡å¼ï¼šæ”¶é›†åŠ¨ä½œæ•°æ®"""
        try:
            # åˆ›å»ºç­–ç•¥æ¥å£
            interface = create_policy_interface(self.config_path, self.policy)
            
            print("å¯åŠ¨ç­–ç•¥æ¥å£...")
            interface.start()
            print("ç­–ç•¥æ¥å£å·²å¯åŠ¨!")
            
            # è·å–åˆå§‹è§‚æµ‹
            obs = interface.get_observation()
            print(f"åˆå§‹å…³èŠ‚ä½ç½®: {obs['robot0_joint_pos']}")
            
            # è¿è¡Œç­–ç•¥å¹¶æ”¶é›†æ•°æ®
            print(f"\nå¼€å§‹è¿è¡Œç­–ç•¥å¹¶æ”¶é›†åŠ¨ä½œæ•°æ®...")
            print(f"æ¨ç†é¢‘ç‡: {self.frequency} Hz")
            print("æŒ‰ Ctrl+C åœæ­¢")
            
            dt = 1.0 / self.frequency
            t_start = time.monotonic()
            step = 0
            
            # è¶…æ—¶é™çº§ç­–ç•¥ç›¸å…³å˜é‡
            last_joint_action = None
            last_gripper_action = None
            inference_times = []
            max_inference_time = 0.18  # æœ€å¤§å…è®¸æ¨ç†æ—¶é—´ (180ms)
            timeout_count = 0
            
            while True:
                if self.max_steps is not None and step >= self.max_steps:
                    print(f"è¾¾åˆ°æœ€å¤§æ­¥æ•° {self.max_steps}ï¼Œåœæ­¢è¿è¡Œ")
                    break
                
                # è®¡ç®—å½“å‰å‘¨æœŸç»“æŸæ—¶é—´
                t_cycle_end = t_start + (step + 1) * dt
                t_cycle_start = time.monotonic()
                
                # è·å–è§‚æµ‹
                obs = interface.get_observation()
                
                # æ‰§è¡Œç­–ç•¥ - æ·»åŠ è¶…æ—¶æ£€æŸ¥
                t_inference_start = time.monotonic()
                try:
                    cur_action = self.policy(obs)
                    joint_action = cur_action[:self.policy.joint_dim]
                    gripper_action = cur_action[self.policy.joint_dim]
                    t_inference_end = time.monotonic()
                    inference_time = t_inference_end - t_inference_start
                    inference_times.append(inference_time)
                    
                    # æ›´æ–°æœ€åæœ‰æ•ˆçš„åŠ¨ä½œ
                    last_joint_action = joint_action.copy()
                    last_gripper_action = gripper_action.copy()
                    timeout_count = 0
                    
                except Exception as e:
                    print(f"æ¨ç†å¤±è´¥: {e}")
                    t_inference_end = time.monotonic()
                    inference_time = t_inference_end - t_inference_start
                    inference_times.append(inference_time)
                    timeout_count += 1
                
                # æ£€æŸ¥æ˜¯å¦è¶…æ—¶
                current_time = time.monotonic()
                elapsed_time = current_time - t_cycle_start
                remaining_time = t_cycle_end - current_time
                
                # å¦‚æœæ¨ç†æ—¶é—´è¿‡é•¿æˆ–å‰©ä½™æ—¶é—´ä¸è¶³ï¼Œä½¿ç”¨é™çº§ç­–ç•¥
                if (inference_time > max_inference_time or 
                    remaining_time < 0.01):  # å‰©ä½™æ—¶é—´å°‘äº10ms
                    
                    if last_joint_action is not None and last_gripper_action is not None:
                        # ä½¿ç”¨ä¸Šæ¬¡çš„æœ‰æ•ˆåŠ¨ä½œ
                        joint_action = last_joint_action
                        gripper_action = last_gripper_action
                        print(f"âš ï¸  ä½¿ç”¨é™çº§ç­–ç•¥: æ¨ç†æ—¶é—´={inference_time:.3f}s, å‰©ä½™æ—¶é—´={remaining_time:.3f}s")
                        
                        # è®°å½•é™çº§ç­–ç•¥çš„ä½¿ç”¨æƒ…å†µ
                        fallback_action = np.concatenate([joint_action, [gripper_action]])
                        self.data_collector.add_action(fallback_action, inference_time, "fallback")
                        
                    else:
                        # ä¸è¦ä½¿ç”¨å½“å‰ä½ç½®ï¼Œè€Œæ˜¯è·³è¿‡è¿™æ¬¡æ‰§è¡Œ
                        joint_action = obs['robot0_joint_pos'] + np.random.normal(0, 0.001, 7)
                        gripper_action = 0.04  # é»˜è®¤å¤¹çˆªå®½åº¦
                        print(f"âš ï¸  ä½¿ç”¨éšæœºæ‰°åŠ¨åŠ¨ä½œï¼Œç­‰å¾…æœ‰æ•ˆæ¨ç†: æ¨ç†æ—¶é—´={inference_time:.3f}s")
                        
                        # è®°å½•éšæœºæ‰°åŠ¨åŠ¨ä½œ
                        random_action = np.concatenate([joint_action, [gripper_action]])
                        self.data_collector.add_action(random_action, inference_time, "random")
                        continue  # è·³è¿‡è¿™æ¬¡å¾ªç¯
                else:
                    # æ­£å¸¸æƒ…å†µï¼Œæ”¶é›†åŸå§‹åŠ¨ä½œæ•°æ®
                    cur_action = np.concatenate([joint_action, [gripper_action]])
                    self.data_collector.add_action(cur_action, inference_time, "normal")
                
                # æ‰§è¡ŒåŠ¨ä½œï¼ˆåœ¨å®é™…æœºå™¨äººä¸Šï¼‰
                interface.execute_action(joint_action)
                interface.execute_gripper_action(gripper_action)
                
                # æ¯10æ­¥æ‰“å°ä¸€æ¬¡è¯¦ç»†ä¿¡æ¯
                if step % 10 == 0:
                    current_time = time.monotonic() - t_start
                    avg_inference_time = np.mean(inference_times[-10:]) if len(inference_times) >= 10 else np.mean(inference_times)
                    print(f"Step {step}: æ—¶é—´={current_time:.2f}s, æ¨ç†æ—¶é—´={inference_time:.3f}s (å¹³å‡={avg_inference_time:.3f}s)")
                    print(f"  å…³èŠ‚åŠ¨ä½œ: {joint_action}")
                    print(f"  GripperåŠ¨ä½œ: {gripper_action}")
                    if timeout_count > 0:
                        print(f"  è¶…æ—¶æ¬¡æ•°: {timeout_count}")
                
                step += 1
                
                # ç­‰å¾…åˆ°ä¸‹ä¸€ä¸ªå‘¨æœŸ
                precise_wait(t_cycle_end)
                
        except KeyboardInterrupt:
            print("\nç”¨æˆ·ä¸­æ–­ï¼Œåœæ­¢ç­–ç•¥...")
        except Exception as e:
            print(f"å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
        finally:
            # åœæ­¢ç­–ç•¥æ¥å£
            if 'interface' in locals():
                print("åœæ­¢ç­–ç•¥æ¥å£...")
                interface.stop()
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if hasattr(self, 'camera_system'):
            self.camera_system.close()


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="å…³èŠ‚åŠ¨ä½œçªå˜åˆ†æè„šæœ¬")
    parser.add_argument("--model_path", type=str, 
                       default="/home/robotflow/Downloads/060000/pretrained_model",
                       help="è®­ç»ƒå¥½çš„æ¨¡å‹è·¯å¾„")
    parser.add_argument("--device", type=str, default="cuda",
                       help="è®¡ç®—è®¾å¤‡ (cpu/cuda)")
    parser.add_argument("--config_path", type=str,
                       default="/home/robotflow/my_code/other_codes/franka_control-main/config/robot_config.yaml",
                       help="æœºå™¨äººé…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--max_steps", type=int, default=1000,
                       help="æœ€å¤§è¿è¡Œæ­¥æ•°")
    parser.add_argument("--test_mode", action="store_true", default=False,
                       help="æµ‹è¯•æ¨¡å¼ï¼ˆä¸è¿æ¥çœŸå®æœºå™¨äººï¼‰")
    parser.add_argument("--frequency", type=float, default=10.0,
                       help="æ¨ç†é¢‘ç‡ (Hz)")
    parser.add_argument("--use_eih", action="store_true", default=True,
                       help="ä½¿ç”¨eye-in-handè§†è§’ä½œä¸ºè¾“å…¥")
    args = parser.parse_args()
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    if not os.path.exists(args.config_path):
        print(f"é”™è¯¯: é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.config_path}")
        return 1
    
    # æ£€æŸ¥æ¨¡å‹è·¯å¾„
    if not os.path.exists(args.model_path):
        print(f"é”™è¯¯: æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {args.model_path}")
        return 1
    
    # åˆ›å»ºå¹¶è¿è¡Œè°ƒè¯•æ¨ç†è¿è¡Œå™¨
    try:
        runner = DebugActionInferenceRunner(
            model_path=args.model_path,
            config_path=args.config_path,
            device=args.device,
            max_steps=args.max_steps,
            test_mode=args.test_mode,
            frequency=args.frequency,
            use_eih=args.use_eih
        )
        
        # è¿è¡Œæ¨ç†å¹¶åˆ†æ
        runner.run_with_visualization()
        
    except Exception as e:
        print(f"åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    print("å…³èŠ‚åŠ¨ä½œçªå˜åˆ†æå®Œæˆ")
    return 0


if __name__ == "__main__":
    exit(main())