#!/usr/bin/env python3
"""
åŸºäºRISEæ¨¡å‹çš„å®æ—¶æ¨ç†è„šæœ¬ - Frankaæœºå™¨äººéƒ¨ç½²

å¿«é€Ÿå¯åŠ¨:
  python inference_with_policy_interface_rise.py

é»˜è®¤å‚æ•°:
  - æµ‹è¯•æ¨¡å¼: True (ä¸è¿æ¥çœŸå®æœºå™¨äºº)
  - æ¨ç†é¢‘ç‡: 5.0 Hz
  - è®¡ç®—è®¾å¤‡: cuda
  - æœ€å¤§æ­¥æ•°: 1000
  - æ¨¡å‹è·¯å¾„: è‡ªåŠ¨æœç´¢ RISE/logs/my_task/policy_last.ckpt
  - é…ç½®æ–‡ä»¶: è‡ªåŠ¨æœç´¢ franka_control/config/robot_config.yaml

åŠŸèƒ½:
  - æ”¯æŒRealSense D415æ·±åº¦ç›¸æœº
  - åŸºäºç‚¹äº‘çš„RISEç­–ç•¥æ¨ç†
  - å®æ—¶æœºå™¨äººæ§åˆ¶ï¼ˆå¯é€‰ï¼‰
  - æ™ºèƒ½è·¯å¾„æœç´¢å’Œé”™è¯¯å¤„ç†
"""

import os
from shlex import join
import numpy as np
import torch
import time
from pathlib import Path
import argparse
from PIL import Image
import cv2
import math
from safetensors.torch import load_file
import sys
import yaml

# æ·»åŠ é¡¹ç›®è·¯å¾„åˆ°sys.pathï¼Œç¡®ä¿ä¼˜å…ˆä½¿ç”¨é¡¹ç›®ä¸­çš„lerobotåº“
project_dir = Path(__file__).parent.parent
model_lerobot_path = project_dir / "model" / "lerobot" / "src"
r3kit_path = project_dir / "model" / "r3kit"
sys.path.insert(0, str(model_lerobot_path))
sys.path.insert(0, str(r3kit_path))  # æ·»åŠ r3kitè·¯å¾„
sys.path.insert(0, str(project_dir))  # æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„

# ç°åœ¨å¯ä»¥å¯¼å…¥é¡¹ç›®å†…çš„æ¨¡å—
from common.gripper_util import convert_gripper_width_to_encoder

# å¯¼å…¥ RISE ç­–ç•¥ï¼ˆåŸºäº my_train.py å’Œ eval.pyï¼‰
import sys
rise_path = Path(__file__).parent.parent / "RISE"
sys.path.insert(0, str(rise_path))

# æ·»åŠ RISEä¾èµ–è·¯å¾„
minkowski_path = rise_path / "dependencies" / "MinkowskiEngine"
pytorch3d_path = rise_path / "dependencies" / "pytorch3d"
sys.path.insert(0, str(minkowski_path))
sys.path.insert(0, str(pytorch3d_path))

# å¯¼å…¥å¿…è¦çš„åº“
try:
    import open3d as o3d
    import MinkowskiEngine as ME
    from policy import RISE
    from dataset.projector import Projector
    from utils.constants import IMG_MEAN, IMG_STD, WORKSPACE_MIN, WORKSPACE_MAX
    RISE_AVAILABLE = True
except ImportError as e:
    print(f"è­¦å‘Š: RISEç›¸å…³åº“å¯¼å…¥å¤±è´¥: {e}")
    RISE_AVAILABLE = False

# å¯¼å…¥PolicyInterface
from policy_interface import create_policy_interface

# å¯¼å…¥precise_wait
from common.precise_sleep import precise_wait

# ç›¸æœºç›¸å…³å¯¼å…¥
import pyrealsense2 as rs
from r3kit.devices.camera.realsense import config as rs_cfg
from r3kit.devices.camera.realsense.d415 import D415
R3KIT_RS_AVAILABLE = True

# D415 ç›¸æœºé…ç½®ï¼ˆä¸é‡‡é›†è„šæœ¬ä¿æŒä¸€è‡´ï¼‰
FPS = 30
D415_CAMERAS = {   
    "cam4": "327322062498",  # å›ºå®šæœºä½è§†è§’
}

class CameraSystem:
    """ç›¸æœºç³»ç»Ÿæ¥å£"""
    
    def __init__(self):
        self.cameras = {}
        self.camera_names = ["cam4"]  # æ”¯æŒåŒè§†è§’
        self.use_realsense = True
        
        # æµé…ç½®
        rs_cfg.D415_STREAMS = [
            (rs.stream.depth, 640,480, rs.format.z16, FPS),
            (rs.stream.color, 640,480, rs.format.bgr8, FPS),
        ]
        for name in self.camera_names:
            serial = D415_CAMERAS.get(name)
            if serial is None:
                print(f"{name} ç¼ºå°‘åºåˆ—å·ï¼Œè·³è¿‡")
                continue
            try:
                cam = D415(id=serial, depth=True, name=name)
                self.cameras[name] = cam
                print(f"æˆåŠŸåˆå§‹åŒ–ç›¸æœº {name} (åºåˆ—å·: {serial})")
            except Exception as e:
                print(f"åˆå§‹åŒ–ç›¸æœº {name} å¤±è´¥: {e}")
                continue
                
        if len(self.cameras) > 0:
            self.use_realsense = True
            print(f"ä½¿ç”¨ RealSense D415ï¼Œç›¸æœºæ•°é‡: {len(self.cameras)}")
            print(f"å¯ç”¨ç›¸æœº: {list(self.cameras.keys())}")
        else:
            print("è­¦å‘Š: æ²¡æœ‰æˆåŠŸåˆå§‹åŒ–ä»»ä½•ç›¸æœº")
    
    def get_image(self, cam_name):
        """è·å–æŒ‡å®šç›¸æœºçš„å›¾åƒ"""
        if cam_name not in self.cameras:
            return None
        
        try:
            if self.use_realsense:
                # r3kit D415 æ¥å£
                color, depth = self.cameras[cam_name].get()
                if color is None:
                    return None
                # è½¬ RGB
                frame_rgb = cv2.cvtColor(color, cv2.COLOR_BGR2RGB)
                return frame_rgb
            else:
                # OpenCV æ‘„åƒå¤´
                ret, frame = self.cameras[cam_name].read()
                if ret:
                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    return frame_rgb
                return None
        except Exception as e:
            print(f"è·å– {cam_name} å›¾åƒå¤±è´¥: {e}")
            return None
    
    def get_depth(self, cam_name):
        """è·å–æŒ‡å®šç›¸æœºçš„æ·±åº¦"""
        if cam_name not in self.cameras:
            return None
        
        try:
            if self.use_realsense:
                # r3kit D415 æ¥å£
                color, depth = self.cameras[cam_name].get()
                return depth
        except Exception as e:
            print(f"è·å– {cam_name} æ·±åº¦å¤±è´¥: {e}")
            return None

    def get_all_images(self):
        """è·å–æ‰€æœ‰ç›¸æœºçš„å›¾åƒ"""
        images = {}
        for cam_name in self.camera_names:
            image = self.get_image(cam_name)
            if image is not None:
                images[cam_name] = image
            else:
                # ç”Ÿæˆæ¨¡æ‹Ÿå›¾åƒä½œä¸º fallback
                images[cam_name] = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
                print(f"è­¦å‘Š: {cam_name} ç›¸æœºå›¾åƒè·å–å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿå›¾åƒ")
        
        return images
    
    def get_image_and_depth(self, cam_name):
        """è·å–æŒ‡å®šç›¸æœºçš„å›¾åƒå’Œæ·±åº¦"""
        if cam_name not in self.cameras:
            return None, None
        
        return self.get_image(cam_name), self.get_depth(cam_name)
    
    def close(self):
        """å…³é—­æ‰€æœ‰ç›¸æœº"""
        for cam_name, cap in self.cameras.items():
            try:
                if self.use_realsense:
                    # D415 ç±»å¯èƒ½æ²¡æœ‰ stop æ–¹æ³•ï¼Œä½¿ç”¨ __del__ æˆ–è€…ä¸åšä»»ä½•æ“ä½œ
                    if hasattr(cap, 'stop'):
                        cap.stop()
                    elif hasattr(cap, 'close'):
                        cap.close()
                    # å¯¹äº r3kit D415ï¼Œé€šå¸¸ç”±ææ„å‡½æ•°è‡ªåŠ¨å¤„ç†
                else:
                    cap.release()
                print(f"{cam_name} å·²å…³é—­")
            except Exception as e:
                print(f"å…³é—­ {cam_name} å¤±è´¥: {e}")


class RISEPolicyWrapper:
    """RISEç­–ç•¥åŒ…è£…å™¨ - åŸºäºç‚¹äº‘å’ŒMinkowskiEngineçš„ç­–ç•¥"""
    
    def __init__(self, model_path, device="cpu", camera_system=None, debug_image=False):
        if not RISE_AVAILABLE:
            raise ImportError("RISEç›¸å…³åº“æœªæ­£ç¡®å®‰è£…ï¼Œè¯·æ£€æŸ¥ä¾èµ–")
            
        self.device = torch.device(device)
        self.model_path = Path(model_path)
        self.camera_system = camera_system
        self.debug_image = debug_image
        
        # é…ç½®å‚æ•° - åŸºäº RISE æ¨¡å‹
        self.camera_names = ["cam4"]  # æ”¯æŒåŒè§†è§’
        self.joint_dim = 7  # 7ä¸ªå…³èŠ‚è§’åº¦ï¼ˆå¼§åº¦ï¼‰  
        self.gripper_dim = 1  # 1ä¸ªå¤¹çˆªå¼€åˆå€¼  
        self.action_dim = self.joint_dim + self.gripper_dim  # æ€»å…±8ç»´  
        
        # RISE æ¨¡å‹å‚æ•°
        self.num_action = 20  # åŠ¨ä½œåºåˆ—é•¿åº¦
        self.voxel_size = 0.005  # ä½“ç´ å¤§å°
        self.obs_feature_dim = 512  # è§‚æµ‹ç‰¹å¾ç»´åº¦
        self.hidden_dim = 512  # éšè—å±‚ç»´åº¦
        self.nheads = 8  # æ³¨æ„åŠ›å¤´æ•°
        self.num_encoder_layers = 4  # ç¼–ç å™¨å±‚æ•°
        self.num_decoder_layers = 1  # è§£ç å™¨å±‚æ•°
        self.dropout = 0.1  # dropoutç‡
        self.action_queue = []
        
        # è°ƒè¯•ä¸ç‚¹äº‘ä¿å­˜é…ç½®
        self.dump_limit = 20
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        self.dump_dir = Path("debug_pointclouds") / timestamp
        try:
            self.dump_dir.mkdir(parents=True, exist_ok=True)
        except Exception:
            pass
        self.dump_count = 0
        self._debug_cache = {
            "raw_points": None,
            "raw_colors": None,
            "proc_points": None,
            "proc_colors": None,
        }
        
        # åŠ è½½æ¨¡å‹
        self.policy = self._load_policy()
        
        print(f"RISEç­–ç•¥åˆå§‹åŒ–å®Œæˆ: {model_path}")
        print(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
        print(f"ç›¸æœºç³»ç»ŸçŠ¶æ€: {len(self.camera_system.cameras) if self.camera_system else 0} ä¸ªç›¸æœºå·²åˆå§‹åŒ–")
    
    def _load_policy(self):
        """åŠ è½½è®­ç»ƒå¥½çš„RISEç­–ç•¥æ¨¡å‹"""
        if not self.model_path.exists():
            raise FileNotFoundError(f"æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {self.model_path}")
        
        policy = RISE(
            num_action=self.num_action,
            input_dim=6,  # ç‚¹äº‘ç‰¹å¾ç»´åº¦ï¼š3Dåæ ‡ + 3Dé¢œè‰²
            obs_feature_dim=self.obs_feature_dim,
            action_dim=8,  # 7ä¸ªå…³èŠ‚ + 1ä¸ªå¤¹çˆª
            hidden_dim=self.hidden_dim,
            nheads=self.nheads,
            num_encoder_layers=self.num_encoder_layers,
            num_decoder_layers=self.num_decoder_layers,
            dropout=self.dropout
        ).to(self.device)
        
        checkpoint = torch.load(self.model_path, map_location=self.device)
        policy.load_state_dict(checkpoint, strict=False)
        
        print(f"RISEæ¨¡å‹åŠ è½½æˆåŠŸ:")
        print(f" æ¨¡å‹ç±»å‹: RISE (åŸºäºç‚¹äº‘çš„ç­–ç•¥)")
        print(f" è®¾å¤‡: {next(policy.parameters()).device}")
        print(f" åŠ¨ä½œåºåˆ—é•¿åº¦: {self.num_action}")
        print(f" ä½“ç´ å¤§å°: {self.voxel_size}")
        print(f" è§‚æµ‹ç‰¹å¾ç»´åº¦: {self.obs_feature_dim}")
        print(f" éšè—å±‚ç»´åº¦: {self.hidden_dim}")
        print(f" æ³¨æ„åŠ›å¤´æ•°: {self.nheads}")
        print(f" ç¼–ç å™¨å±‚æ•°: {self.num_encoder_layers}")
        print(f" è§£ç å™¨å±‚æ•°: {self.num_decoder_layers}")
        
        return policy
    
    def create_point_cloud(self, color_image, depth_image, cam_intrinsics):
        """
        ä»RGB-Då›¾åƒåˆ›å»ºç‚¹äº‘ï¼ˆåŸºäº eval.pyï¼‰
        """
        h, w = depth_image.shape
        fx, fy = cam_intrinsics[0, 0], cam_intrinsics[1, 1]
        cx, cy = cam_intrinsics[0, 2], cam_intrinsics[1, 2]

        colors = o3d.geometry.Image(color_image.astype(np.uint8))
        # æ·±åº¦å›¾å•ä½è½¬æ¢ï¼šä»æ¯«ç±³è½¬æ¢ä¸ºç±³
        if depth_image.dtype == np.uint16:
            depth_float = depth_image.astype(np.float32) / 1000.0  # æ¯«ç±³è½¬ç±³
        else:
            depth_float = depth_image.astype(np.float32)
        depths = o3d.geometry.Image(depth_float)

        camera_intrinsics = o3d.camera.PinholeCameraIntrinsic(
            width=w, height=h, fx=fx, fy=fy, cx=cx, cy=cy
        )
        rgbd = o3d.geometry.RGBDImage.create_from_color_and_depth(
            colors, depths, depth_scale=1.0, convert_rgb_to_intensity=False
        )
        cloud = o3d.geometry.PointCloud.create_from_rgbd_image(rgbd, camera_intrinsics)
        cloud = cloud.voxel_down_sample(self.voxel_size)
        points = np.array(cloud.points).astype(np.float32)
        colors = np.array(cloud.colors).astype(np.float32)

        # è®°å½•ä¸‹é‡‡æ ·åçš„åŸå§‹ç‚¹äº‘ï¼ˆæœªè£å‰ª/æœªå½’ä¸€åŒ–ï¼‰
        raw_points = points.copy()
        raw_colors = colors.copy()

        # å·¥ä½œç©ºé—´è£å‰ª
        x_mask = ((points[:, 0] >= WORKSPACE_MIN[0]) & (points[:, 0] <= WORKSPACE_MAX[0]))
        y_mask = ((points[:, 1] >= WORKSPACE_MIN[1]) & (points[:, 1] <= WORKSPACE_MAX[1]))
        z_mask = ((points[:, 2] >= WORKSPACE_MIN[2]) & (points[:, 2] <= WORKSPACE_MAX[2]))
        mask = (x_mask & y_mask & z_mask)
        points = points[mask]
        colors = colors[mask]
        
        # ImageNetå½’ä¸€åŒ–
        colors_norm = (colors - IMG_MEAN) / IMG_STD
        
        # åˆå¹¶ç‚¹å’Œé¢œè‰²
        cloud_final = np.concatenate([points, colors_norm], axis=-1).astype(np.float32)

        # ä¿å­˜å¤„ç†åçš„ï¼ˆä¼ å…¥ç­–ç•¥å‰çš„ï¼‰ç‚¹äº‘ç¼“å­˜
        self._debug_cache["raw_points"] = raw_points
        self._debug_cache["raw_colors"] = raw_colors
        self._debug_cache["proc_points"] = points
        self._debug_cache["proc_colors"] = colors  # éå½’ä¸€åŒ–ï¼Œç”¨äºå¯è§†åŒ–

        return cloud_final
    
    def create_batch(self, coords, feats):
        coords_batch = [coords]
        feats_batch = [feats]
        coords_batch, feats_batch = ME.utils.sparse_collate(coords_batch, feats_batch)
        return coords_batch, feats_batch
    
    def create_input(self, color_image, depth_image, cam_intrinsics):
        """
        ä»RGB-Då›¾åƒåˆ›å»ºè¾“å…¥ï¼ˆåŸºäº eval.pyï¼‰
        """
        cloud = self.create_point_cloud(color_image, depth_image, cam_intrinsics)
        
        # æ£€æŸ¥ç‚¹äº‘æ˜¯å¦ä¸ºç©º - å¦‚æœä¸ºç©ºï¼Œè¯´æ˜ç›¸æœºæ•°æ®æˆ–å¤„ç†æœ‰é—®é¢˜
        if len(cloud) == 0:
            print("è­¦å‘Š: ç‚¹äº‘ä¸ºç©ºï¼Œæ£€æŸ¥ç›¸æœºæ•°æ®å’Œé¢„å¤„ç†")
            # ç”Ÿæˆä¸€ä¸ªåˆç†çš„æ¨¡æ‹Ÿç‚¹äº‘è€Œä¸æ˜¯å•ç‚¹é»˜è®¤å€¼
            cloud = np.random.uniform(-0.3, 0.3, (1000, 6)).astype(np.float32)
            cloud[:, 3:] = (cloud[:, 3:] - IMG_MEAN) / IMG_STD  # é¢œè‰²å½’ä¸€åŒ–
        
        # æ£€æŸ¥ç‚¹äº‘æ•°æ®æ˜¯å¦æœ‰æ•ˆ
        if np.any(np.isnan(cloud)) or np.any(np.isinf(cloud)):
            print("è­¦å‘Š: ç‚¹äº‘åŒ…å«æ— æ•ˆå€¼ï¼Œè¿›è¡Œæ¸…ç†")
            valid_mask = ~(np.isnan(cloud).any(axis=1) | np.isinf(cloud).any(axis=1))
            cloud = cloud[valid_mask]
            
            if len(cloud) == 0:
                print("è­¦å‘Š: æ¸…ç†åç‚¹äº‘ä¸ºç©ºï¼Œä½¿ç”¨æ¨¡æ‹Ÿç‚¹äº‘")
                cloud = np.random.uniform(-0.3, 0.3, (1000, 6)).astype(np.float32)
                cloud[:, 3:] = (cloud[:, 3:] - IMG_MEAN) / IMG_STD
        
        coords = np.ascontiguousarray(cloud[:, :3] / self.voxel_size, dtype=np.int32)
        
        # æ£€æŸ¥åæ ‡èŒƒå›´
        if np.any(np.abs(coords) > 100000):  # é˜²æ­¢åæ ‡è¿‡å¤§
            print("è­¦å‘Š: åæ ‡å€¼è¿‡å¤§ï¼Œè¿›è¡Œè£å‰ª")
            coords = np.clip(coords, -100000, 100000)
        
        coords_batch, feats_batch = self.create_batch(coords, cloud)

        # æ¡ä»¶ä¿å­˜ç‚¹äº‘ï¼ˆæœ€å¤š20å¸§ï¼Œä¸å½±å“æ¨ç†æµç¨‹ï¼‰
        try:
            if self.dump_count < self.dump_limit and self.dump_dir is not None:
                self._dump_pointclouds(coords=coords, cloud=cloud)
                self.dump_count += 1
        except Exception:
            pass

        return coords_batch, feats_batch, cloud

    def _dump_pointclouds(self, coords: np.ndarray, cloud: np.ndarray):
        """ä¿å­˜ä¸€å¸§ç‚¹äº‘åˆ°ç£ç›˜ï¼ŒåŒ…æ‹¬ï¼š
        - raw: ä¸‹é‡‡æ ·åä½†æœªè£å‰ª/æœªå½’ä¸€åŒ–çš„ç‚¹äº‘ï¼ˆPLY/NPZï¼‰
        - proc: è£å‰ªåç”¨äºç­–ç•¥çš„ç‚¹äº‘ï¼ˆå»è£å‰ªåçš„ points ä¸æœªå½’ä¸€åŒ– colorsï¼‰ï¼ˆPLY/NPZï¼‰
        - final: ç¨€ç–åæ ‡ï¼ˆintï¼‰ä¸è¿˜åŸç©ºé—´åæ ‡ï¼ˆPLY/NPZï¼‰
        """
        idx = f"{self.dump_count:04d}"
        raw_pts = self._debug_cache.get("raw_points")
        raw_cols = self._debug_cache.get("raw_colors")
        proc_pts = self._debug_cache.get("proc_points")
        proc_cols = self._debug_cache.get("proc_colors")

        # è¿˜åŸç”¨äºå¯è§†åŒ–çš„é¢œè‰²åˆ° [0,1]
        def make_o3d_pcd(points_f32: np.ndarray, colors_f32: np.ndarray):
            pcd = o3d.geometry.PointCloud()
            pcd.points = o3d.utility.Vector3dVector(points_f32.astype(np.float64))
            colors_vis = np.clip(colors_f32, 0.0, 1.0)
            pcd.colors = o3d.utility.Vector3dVector(colors_vis.astype(np.float64))
            return pcd

        # ä¿å­˜ raw ç‚¹äº‘
        if raw_pts is not None and raw_cols is not None and len(raw_pts) > 0:
            pcd_raw = make_o3d_pcd(raw_pts, raw_cols)
            o3d.io.write_point_cloud(str(self.dump_dir / f"{idx}_raw.ply"), pcd_raw, write_ascii=True)

        # ä¿å­˜ proc ç‚¹äº‘ï¼ˆè£å‰ªåï¼Œé¢œè‰²åå½’ä¸€åŒ–ç”¨äºå¯è§†åŒ–ï¼‰
        if proc_pts is not None and proc_cols is not None and len(proc_pts) > 0:
            # åå½’ä¸€åŒ–å¯è§†åŒ–
            proc_cols_vis = np.clip(proc_cols, 0.0, 1.0)
            pcd_proc = make_o3d_pcd(proc_pts, proc_cols_vis)
            o3d.io.write_point_cloud(str(self.dump_dir / f"{idx}_proc.ply"), pcd_proc, write_ascii=True)

        # ä¿å­˜ final ç¨€ç–åæ ‡ï¼ˆå°†ä½“ç´ åæ ‡è¿˜åŸä¸ºç±³ï¼‰
        if coords is not None and len(coords) > 0:
            coords_xyz = coords.astype(np.float32) * float(self.voxel_size)
            # ä¸ proc_pts å¯¹é½ï¼ˆé•¿åº¦åº”ä¸€è‡´ï¼‰
            final_cols = proc_cols if (proc_cols is not None and len(proc_cols) == len(coords_xyz)) else np.ones_like(coords_xyz)
            final_cols_vis = np.clip(final_cols, 0.0, 1.0)
            pcd_final = make_o3d_pcd(coords_xyz, final_cols_vis)
            o3d.io.write_point_cloud(str(self.dump_dir / f"{idx}_final_sparse.ply"), pcd_final, write_ascii=True)

        # ä¿å­˜æ•°å€¼æ•°æ®ä¸º npz
        np.savez_compressed(
            str(self.dump_dir / f"{idx}_data.npz"),
            raw_points=raw_pts,
            raw_colors=raw_cols,
            proc_points=proc_pts,
            proc_colors=proc_cols,
            final_coords_int=coords,
            final_coords_xyz=(coords.astype(np.float32) * float(self.voxel_size)) if coords is not None else None,
            cloud_to_policy=cloud,  # (N,6) = [x,y,z, r_norm,g_norm,b_norm]
        )
    
    def unnormalize_action(self, action):
        """
        åå½’ä¸€åŒ–åŠ¨ä½œï¼ˆåŸºäº myworld.py çš„è®­ç»ƒæ—¶å½’ä¸€åŒ–æ–¹å¼ï¼‰
        
        Args:
            action: å½’ä¸€åŒ–çš„åŠ¨ä½œ (..., 8) - å‰7ç»´å…³èŠ‚è§’åº¦ï¼Œç¬¬8ç»´å¤¹çˆªå®½åº¦
        
        Returns:
            action: åå½’ä¸€åŒ–åçš„åŠ¨ä½œ
                - å‰7ç»´ï¼šå…³èŠ‚è§’åº¦ï¼ˆå¼§åº¦ï¼‰ï¼ŒèŒƒå›´ [-Ï€, Ï€]
                - ç¬¬8ç»´ï¼šå¤¹çˆªå®½åº¦ï¼ˆç±³ï¼‰ï¼ŒèŒƒå›´ [0, 0.08]
        """
        action = action.copy()
        
        # åå½’ä¸€åŒ–å…³èŠ‚è§’åº¦ï¼šä» [-1, 1] æ¢å¤åˆ° [-Ï€, Ï€]
        action[..., :7] = action[..., :7] * np.pi
        
        # åå½’ä¸€åŒ–å¤¹çˆªå®½åº¦ï¼šä» [-1, 1] æ¢å¤åˆ° [0, 0.08]
        # è®­ç»ƒæ—¶ï¼šgripper_norm = (gripper - 0.0) / 0.08 * 2 - 1
        # åæ¨ï¼šgripper = (gripper_norm + 1) * 0.08 / 2
        action[..., 7] = (action[..., 7] + 1) * 0.08 / 2
        
        return action
    
    def get_current_state_with_gripper(self, obs):
        """ä»è§‚æµ‹ä¸­è·å–å½“å‰çŠ¶æ€ï¼ˆ8ç»´ï¼‰"""
        joints_rad = obs['robot0_joint_pos']  # (7,)
        
        if 'robot0_gripper_width' in obs:
            gripper_width = obs['robot0_gripper_width']
            if isinstance(gripper_width, np.ndarray):
                gripper_width = gripper_width[0] if len(gripper_width) > 0 else 0.04
        else:
            gripper_width = 0.04  # é»˜è®¤å¤¹çˆªå®½åº¦ï¼ˆç±³ï¼‰
        
        # è¿”å›8ç»´çŠ¶æ€ï¼š7ä¸ªå…³èŠ‚è§’åº¦ï¼ˆå¼§åº¦ï¼‰ + 1ä¸ªå¤¹çˆªå®½åº¦ï¼ˆç±³ï¼‰
        return np.concatenate([joints_rad, [gripper_width]])
    
    def preprocess_image(self, image, depth):
        """
        æ ¹æ®RGBå›¾åƒå¯¹é½è£å‰ªæ·±åº¦å›¾
        
        Args:
            image: RGBå›¾åƒ (480, 640, 3) uint8
            depth: æ·±åº¦å›¾ (480, 640) uint16 æ¯«ç±³å•ä½
        
        Returns:
            cropped_rgb: è£å‰ªåçš„RGBå›¾åƒ
            cropped_depth: è£å‰ªåçš„æ·±åº¦å›¾
        """
        # ç¡®ä¿è¾“å…¥æ˜¯numpyæ•°ç»„
        if isinstance(image, Image.Image):
            image = np.array(image)
        if isinstance(depth, Image.Image):
            depth = np.array(depth)
        
        # è·å–åŸå§‹å›¾åƒå°ºå¯¸
        h, w = image.shape[:2]
        start_w = 180
        end_w = 540
        start_h = 0
        end_h = 360

        # è£å‰ªæ·±åº¦å›¾å’ŒRGBå›¾
        cropped_depth = depth[start_h:end_h, start_w:end_w]
        cropped_rgb = image[start_h:end_h, start_w:end_w]
        
        return cropped_rgb, cropped_depth

    
    def predict_single_action(self, images, current_state, cam_intrinsics):
        """
        å•æ­¥é¢„æµ‹åŠ¨ä½œï¼ˆä½¿ç”¨ RISE ç­–ç•¥ï¼‰ã€‚
        è¿”å›: (8,) numpy æ•°ç»„ï¼Œå‰7ç»´ä¸ºå…³èŠ‚(å¼§åº¦)ï¼Œç¬¬8ç»´ä¸ºå¤¹çˆª(ç±³)ã€‚
        """
        # è·å–RGBå’Œæ·±åº¦å›¾åƒ
        if "cam4" in images:
            color_img, depth_img = self.camera_system.get_image_and_depth("cam4")
        else:
            # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
            color_img = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
            depth_img = np.ones((480, 640), dtype=np.float32) * 0.5
            print("è­¦å‘Š: å›ºå®šæœºä½è§†è§’å›¾åƒè·å–å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
        
        if color_img is None or depth_img is None:
            color_img = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
            depth_img = np.ones((480, 640), dtype=np.float32) * 0.5
            print("è­¦å‘Š: å›¾åƒè·å–å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
        
        color_img, depth_img = self.preprocess_image(color_img, depth_img)
        
        # åˆ›å»ºç‚¹äº‘è¾“å…¥
        coords_batch, feats_batch, cloud = self.create_input(color_img, depth_img, cam_intrinsics)
        feats_batch, coords_batch = feats_batch.to(self.device), coords_batch.to(self.device)
        cloud_data = ME.SparseTensor(feats_batch, coords_batch)

        if len(self.action_queue) == 0:
            with torch.no_grad():
                try:
                    # ç¡®ä¿æ¨¡å‹åœ¨è¯„ä¼°æ¨¡å¼
                    self.policy.eval()
                    
                    # ä½¿ç”¨RISEç­–ç•¥è¿›è¡Œé¢„æµ‹
                    pred_raw_actions = self.policy(cloud_data, actions=None, batch_size=1).squeeze(0).cpu().numpy()
                    
                    # åå½’ä¸€åŒ–åŠ¨ä½œ
                    actions = self.unnormalize_action(pred_raw_actions)
                    
                    for action in actions:
                        self.action_queue.append(action)
                        
                except RuntimeError as e:
                    if "CUDA error: invalid configuration argument" in str(e):
                        print(f"CUDAé…ç½®é”™è¯¯: {e}")
                        print("ä½¿ç”¨é»˜è®¤åŠ¨ä½œä½œä¸ºfallback")
                        # ä½¿ç”¨é»˜è®¤åŠ¨ä½œ
                        default_action = np.zeros(8, dtype=np.float32)
                        default_action[:7] = current_state[:7]  # ä¿æŒå½“å‰å…³èŠ‚ä½ç½®
                        default_action[7] = 0.04  # é»˜è®¤å¤¹çˆªå®½åº¦
                        actions = [default_action]
                        for action in actions:
                            self.action_queue.append(action)
                    else:
                        raise e

        action = self.action_queue.pop(0)
            
        return action
    
    
    def __call__(self, obs):
        """
        ç­–ç•¥å‡½æ•° - PolicyInterfaceå…¼å®¹æ¥å£
        
        Args:
            obs: è§‚æµ‹å­—å…¸ï¼ŒåŒ…å«robot0_joint_posç­‰
            
        Returns:
            action: 8ç»´åŠ¨ä½œ [j1, j2, j3, j4, j5, j6, j7, gripper] (å¼§åº¦, ç±³)
        """
        # è·å–å½“å‰å›¾åƒ
        current_images = self.camera_system.get_all_images()
        
        # è·å–å½“å‰çŠ¶æ€
        current_state = self.get_current_state_with_gripper(obs)
        
        # ç›¸æœºå†…å‚
        cam_intrinsics = np.array([[606.268127441406, 0, 319.728454589844, 0],
                              [0, 605.743286132812, 234.524749755859, 0],
                              [0, 0, 1, 0]])
        
        # å•æ­¥é¢„æµ‹åŠ¨ä½œ
        full_action = self.predict_single_action(current_images, current_state, cam_intrinsics)
        
        joint_action = full_action[:self.joint_dim]
        gripper_width = full_action[self.joint_dim]  # å¤¹çˆªå®½åº¦ï¼ˆç±³ï¼‰

        cur_action = np.concatenate([joint_action, [gripper_width]])
        return cur_action
    
    def check_camera_status(self):
        """æ£€æŸ¥ç›¸æœºçŠ¶æ€"""
        if not self.camera_system:
            print("ç›¸æœºç³»ç»Ÿæœªåˆå§‹åŒ–")
            return False
        
        print("ç›¸æœºçŠ¶æ€æ£€æŸ¥:")
        for cam_name in self.camera_names:
            if cam_name in self.camera_system.cameras:
                print(f"  âœ… {cam_name}: å·²åˆå§‹åŒ–")
            else:
                print(f"  âŒ {cam_name}: æœªåˆå§‹åŒ–")
        
        return len(self.camera_system.cameras) > 0


class RISEInferenceRunner:
    """RISEæ¨ç†è¿è¡Œå™¨ """
    
    def __init__(self, 
                 model_path: str,
                 config_path: str,
                 device: str = "cuda",
                 max_steps: int = 1000,
                 test_mode: bool = False,
                 frequency: float = 20.0,
                 debug_image: bool = False):
        """
        åˆå§‹åŒ–ACTæ¨ç†è¿è¡Œå™¨
        
        Args:
            model_path: æ¨¡å‹è·¯å¾„
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            device: è®¡ç®—è®¾å¤‡
            max_steps: æœ€å¤§è¿è¡Œæ­¥æ•°
            test_mode: æµ‹è¯•æ¨¡å¼
            frequency: æ¨ç†é¢‘ç‡ (Hz)
        """
        self.model_path = model_path
        self.config_path = config_path
        self.device = device
        self.max_steps = max_steps
        self.test_mode = test_mode
        self.frequency = frequency
        self.debug_image = debug_image
        self.dt = 1.0 / frequency  # æ—¶é—´é—´éš”
        
        # åˆ›å»ºç›¸æœºç³»ç»Ÿ
        self.camera_system = CameraSystem()
        
        # åˆ›å»ºRISEç­–ç•¥
        self.policy = RISEPolicyWrapper(
            model_path=model_path,
            device=device,
            camera_system=self.camera_system,
            debug_image=self.debug_image
        )
        
        print(f"RISEæ¨ç†è¿è¡Œå™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"æ¨¡å‹è·¯å¾„: {model_path}")
        print(f"é…ç½®æ–‡ä»¶: {config_path}")
        print(f"è®¾å¤‡: {device}")
        print(f"æµ‹è¯•æ¨¡å¼: {test_mode}")
        print(f"æ¨ç†é¢‘ç‡: {frequency} Hz")
        
        # æ£€æŸ¥ç›¸æœºçŠ¶æ€
        self.policy.check_camera_status()
    
    def run(self):
        """æ‰§è¡Œæ¨ç†"""
        if self.test_mode:
            print("ä½¿ç”¨æµ‹è¯•æ¨¡å¼")
            self._run_test_mode()
        else:
            print("ä½¿ç”¨å®æ—¶æ¨ç†æ¨¡å¼")
            self._run_real_time_mode()
    
    def _run_test_mode(self):
        """æµ‹è¯•æ¨¡å¼ï¼šè¿è¡Œå‡ æ¬¡æ¨ç†"""
        print("å¼€å§‹æµ‹è¯•æ¨ç†...")
        for i in range(3):
            print(f"\n=== æµ‹è¯•æ¨ç† {i + 1} ===")
            # æ¨¡æ‹Ÿè§‚æµ‹æ•°æ®
            obs = {
                'robot0_joint_pos': np.random.uniform(-1, 1, 7),
                'robot0_joint_vel': np.random.uniform(-0.1, 0.1, 7),
                'robot0_eef_pos': np.random.uniform(0.3, 0.7, 3),
                'robot0_eef_rot_axis_angle': np.random.uniform(-1, 1, 3),
                'robot0_gripper_width': np.random.uniform(0.0, 0.08, 1),  # æ·»åŠ gripperå®½åº¦
                'timestamp': time.monotonic()
            }
            
            # æ‰§è¡Œç­–ç•¥
            cur_action = self.policy(obs)
            joint_action = cur_action[:self.policy.joint_dim]
            gripper_action = cur_action[self.policy.joint_dim]
            
            print(f"é¢„æµ‹çš„å…³èŠ‚åŠ¨ä½œï¼ˆ7ç»´ï¼‰: {joint_action}")
            print(f"é¢„æµ‹çš„å¤¹çˆªåŠ¨ä½œï¼ˆ1ç»´ï¼‰: {gripper_action}")
            print(f"é¢„æµ‹çš„å®Œæ•´åŠ¨ä½œï¼ˆ8ç»´ï¼‰: {cur_action}")
            print(f"é¢„æµ‹çš„å¤¹çˆªåŠ¨ä½œ: {gripper_action}")
            
            time.sleep(2)
    
    def _run_real_time_mode(self):
        """å®æ—¶æ¨ç†æ¨¡å¼"""
        try:
            # åˆ›å»ºç­–ç•¥æ¥å£
            interface = create_policy_interface(self.config_path, self.policy)
            
            print("å¯åŠ¨ç­–ç•¥æ¥å£...")
            interface.start()
            print("ç­–ç•¥æ¥å£å·²å¯åŠ¨!")
            
            # è·å–åˆå§‹è§‚æµ‹
            obs = interface.get_observation()
            print(f"åˆå§‹å…³èŠ‚ä½ç½®: {obs['robot0_joint_pos']}")
            print(f"åˆå§‹Gripperå®½åº¦: {obs['robot0_gripper_width']}")
            
            # è¿è¡Œç­–ç•¥
            print(f"\nå¼€å§‹è¿è¡Œç­–ç•¥...")
            print(f"æ¨ç†é¢‘ç‡: {self.frequency} Hz (dt = {self.dt:.3f}s)")
            print("æŒ‰ Ctrl+C åœæ­¢")
            
            # åˆå§‹åŒ–æ—¶é—´æ§åˆ¶
            t_start = time.monotonic()
            step = 0
            
            # è¶…æ—¶é™çº§ç­–ç•¥ç›¸å…³å˜é‡
            last_joint_action = None
            last_gripper_action = None
            inference_times = []
            max_inference_time = 0.18  # æœ€å¤§å…è®¸æ¨ç†æ—¶é—´ (180ms) - é’ˆå¯¹130msæ¨ç†æ—¶é—´ä¼˜åŒ–
            timeout_count = 0
            
            while True:
                if self.max_steps is not None and step >= self.max_steps:
                    print(f"è¾¾åˆ°æœ€å¤§æ­¥æ•° {self.max_steps}ï¼Œåœæ­¢è¿è¡Œ")
                    break
                
                # è®¡ç®—å½“å‰å‘¨æœŸç»“æŸæ—¶é—´
                t_cycle_end = t_start + (step + 1) * self.dt
                t_cycle_start = time.monotonic()
                
                # è·å–è§‚æµ‹
                obs = interface.get_observation()
                
                # æ‰§è¡Œç­–ç•¥ - æ·»åŠ è¶…æ—¶æ£€æŸ¥
                t_inference_start = time.monotonic()
                try:
                    cur_action = self.policy(obs)
                    joint_action = cur_action[:self.policy.joint_dim]
                    gripper_action = cur_action[self.policy.joint_dim]
                    t_inference_end = time.monotonic()
                    inference_time = t_inference_end - t_inference_start
                    inference_times.append(inference_time)
                    
                    # æ›´æ–°æœ€åæœ‰æ•ˆçš„åŠ¨ä½œ
                    last_joint_action = joint_action.copy()
                    last_gripper_action = gripper_action.copy()
                    timeout_count = 0
                    
                except Exception as e:
                    print(f"æ¨ç†å¤±è´¥: {e}")
                    t_inference_end = time.monotonic()
                    inference_time = t_inference_end - t_inference_start
                    inference_times.append(inference_time)
                    timeout_count += 1
                
                # æ£€æŸ¥æ˜¯å¦è¶…æ—¶
                current_time = time.monotonic()
                elapsed_time = current_time - t_cycle_start
                remaining_time = t_cycle_end - current_time
                
                # å¦‚æœæ¨ç†æ—¶é—´è¿‡é•¿æˆ–å‰©ä½™æ—¶é—´ä¸è¶³ï¼Œä½¿ç”¨é™çº§ç­–ç•¥
                if (inference_time > max_inference_time or 
                    remaining_time < 0.01): # å‰©ä½™æ—¶é—´å°‘äº10ms):
                    
                    if last_joint_action is not None and last_gripper_action is not None:
                        # ä½¿ç”¨ä¸Šæ¬¡çš„æœ‰æ•ˆåŠ¨ä½œ
                        joint_action = last_joint_action
                        gripper_action = last_gripper_action
                        print(f"âš ï¸  ä½¿ç”¨é™çº§ç­–ç•¥: æ¨ç†æ—¶é—´={inference_time:.3f}s, å‰©ä½™æ—¶é—´={remaining_time:.3f}s")
                    else:
                        joint_action = obs['robot0_joint_pos'] + np.random.normal(0, 0.001, 7)
                        print(f"âš ï¸  ä½¿ç”¨éšæœºæ‰°åŠ¨åŠ¨ä½œï¼Œç­‰å¾…æœ‰æ•ˆæ¨ç†: æ¨ç†æ—¶é—´={inference_time:.3f}s")
                        continue 
                
                interface.execute_action(joint_action)
                interface.execute_gripper_action(gripper_action)
                
                if step % 10 == 0:
                    current_time = time.monotonic() - t_start
                    avg_inference_time = np.mean(inference_times[-10:]) if len(inference_times) >= 10 else np.mean(inference_times)
                    print(f"Step {step}: æ—¶é—´={current_time:.2f}s, æ¨ç†æ—¶é—´={inference_time:.3f}s (å¹³å‡={avg_inference_time:.3f}s)")
                    print(f"  å…³èŠ‚åŠ¨ä½œ: {joint_action}")
                    print(f"  GripperåŠ¨ä½œ: {gripper_action}")
                    if timeout_count > 0:
                        print(f"  è¶…æ—¶æ¬¡æ•°: {timeout_count}")
                
                step += 1
                
                # ç­‰å¾…åˆ°ä¸‹ä¸€ä¸ªå‘¨æœŸ
                precise_wait(t_cycle_end)
                
        except KeyboardInterrupt:
            print("\nç”¨æˆ·ä¸­æ–­ï¼Œåœæ­¢ç­–ç•¥...")
        except Exception as e:
            print(f"å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
        finally:
            # åœæ­¢ç­–ç•¥æ¥å£
            if 'interface' in locals():
                print("åœæ­¢ç­–ç•¥æ¥å£...")
                interface.stop()
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if hasattr(self, 'camera_system'):
            self.camera_system.close()


def main():
    """ä¸»å‡½æ•°"""
    # è®¾ç½®CUDAç¯å¢ƒå˜é‡
    import os
    os.environ['CUDA_LAUNCH_BLOCKING'] = '1'  # å¯ç”¨CUDAåŒæ­¥è°ƒè¯•
    os.environ['OMP_NUM_THREADS'] = '8'       # é™åˆ¶OpenMPçº¿ç¨‹æ•°
    
    parser = argparse.ArgumentParser(
        description="åŸºäºRISEæ¨¡å‹çš„å®æ—¶æ¨ç†è„šæœ¬",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    # è®¾ç½®é»˜è®¤è·¯å¾„ï¼ˆç›¸å¯¹äºå½“å‰è„šæœ¬ä½ç½®ï¼‰
    script_dir = Path(__file__).parent
    project_root = script_dir.parent.parent
    
    parser.add_argument("--model_path", type=str, 
                       default='/home/robotflow/my_code/other_codes/franka_control/policy_epoch_1000_seed_233.ckpt',
                       help="è®­ç»ƒå¥½çš„RISEæ¨¡å‹è·¯å¾„")
    parser.add_argument("--device", type=str, default="cuda",
                       help="è®¡ç®—è®¾å¤‡ (cpu/cuda)")
    parser.add_argument("--config_path", type=str,
                       default=str(script_dir.parent / "config" / "robot_config.yaml"),
                       help="æœºå™¨äººé…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--max_steps", type=int, default=1000,
                       help="æœ€å¤§è¿è¡Œæ­¥æ•°")
    parser.add_argument("--test_mode", action="store_true", default=False,
                       help="æµ‹è¯•æ¨¡å¼ï¼ˆä¸è¿æ¥çœŸå®æœºå™¨äººï¼‰")
    parser.add_argument("--frequency", type=float, default=2.0,
                       help="æ¨ç†é¢‘ç‡ (Hz) - RISEæ¨¡å‹æ¨ç†è¾ƒæ…¢ï¼Œå»ºè®®5Hz")
    parser.add_argument("--debug_image", action="store_true", default=False,
                       help="æ˜¾ç¤ºå›¾åƒå¤„ç†è°ƒè¯•ä¿¡æ¯")
    
    args = parser.parse_args()
    
    # æ£€æŸ¥å¹¶è®¾ç½®æ¨¡å‹è·¯å¾„
    if not os.path.exists(args.model_path):
        print(f"âš ï¸  é»˜è®¤æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {args.model_path}")
        return 1
    
    # æ£€æŸ¥å¹¶è®¾ç½®é…ç½®æ–‡ä»¶è·¯å¾„
    if not os.path.exists(args.config_path):
        print(f"âš ï¸  é»˜è®¤é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.config_path}")
        return 1
    
    print(f"ğŸ“ ä½¿ç”¨æ¨¡å‹è·¯å¾„: {args.model_path}")
    print(f"ğŸ“ ä½¿ç”¨é…ç½®æ–‡ä»¶: {args.config_path}")
    print(f"ğŸ¯ æµ‹è¯•æ¨¡å¼: {args.test_mode}")
    print(f"âš¡ æ¨ç†é¢‘ç‡: {args.frequency} Hz")
    print(f"ğŸ–¥ï¸  è®¡ç®—è®¾å¤‡: {args.device}")
    print("-" * 50)
    
    print("ğŸš€ å¯åŠ¨RISEæ¨ç†ç³»ç»Ÿ...")
    if args.test_mode:
        print("ğŸ“ è¿è¡Œåœ¨æµ‹è¯•æ¨¡å¼ - ä¸ä¼šè¿æ¥çœŸå®æœºå™¨äºº")
    else:
        print("âš ï¸  è¿è¡Œåœ¨å®æ—¶æ¨¡å¼ - å°†è¿æ¥çœŸå®æœºå™¨äºº!")
        print("   è¯·ç¡®ä¿æœºå™¨äººå·²æ­£ç¡®è¿æ¥å¹¶å¤„äºå®‰å…¨çŠ¶æ€")
    print("-" * 50)
    
    # åˆ›å»ºå¹¶è¿è¡ŒRISEæ¨ç†è¿è¡Œå™¨
    try:
        runner = RISEInferenceRunner(
            model_path=args.model_path,
            config_path=args.config_path,
            device=args.device,
            max_steps=args.max_steps,
            test_mode=args.test_mode,
            frequency=args.frequency,
            debug_image=args.debug_image
        )
        
        # æ‰§è¡Œæ¨ç†
        runner.run()
        
    except Exception as e:
        print(f"æ¨ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1
    finally:
        # æ¸…ç†èµ„æº
        if 'runner' in locals():
            runner.cleanup()
    
    print("æ¨ç†è„šæœ¬æ‰§è¡Œå®Œæˆ")
    return 0


if __name__ == "__main__":
    exit(main())
